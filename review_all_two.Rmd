---
title: "review_all_two"
output: github_document
---

# Data wrangling 1

Let's go!

```{r setup}
library(tidyverse)
library(readxl)
library(haven)
library(dplyr)
```

lets read in some data and clean names

```{r}
litters_df = read_csv("data/FAS_litters.csv")
litters_df =
  janitor::clean_names(litters_df)
```

lets look at info

Printing in the console
```{r}
tail(litters_df)

# looking at the last row of data

skimr::skim(litters_df)

#when you have characters variables is give u a histogram, sd, mean, max, min, info missing

```

so we have <chr> variables that have letters and numbers, then we have <dbl> 
which are numeric variables.


#### options to read_csv

```{r}
litters_df = read_csv("data/FAS_litters.csv", skip = 10, col_names = FALSE,
                      na = c("", "NA", ".", "999"))

# here we are skipping the first 10 lines of data, and then we don't want the
# data to be whatever so we make R make random column names for the table. and
# na tells the data that those things are missing numbers like 

```

when you put ?read_csv... you can learn about this function. more info.

Now lets read in different files
#### read in an excel file

```{r}
mlb_df = read_excel("data/mlb11.xlsx", range = "A1:F7")
mlb_df
# this data set was already cleaned
```

remember you can use ?read_excel to get more info. 

Now lets read in a SAS file

```{r}
pulse_df = read_sas("data/public_pulse_data.sas7bdat")
pulse_df = janitor::clean_names(pulse_df)

```

#### comparison with base R

what about read.csv? It is built into R, but don't use it.

####Okay now to export data
export mlb sub-table

```{r}
#write_csv(mlb_df,"data/mlb_subtable.csv")
```
i put a hash tag so it wont reprint

# Data Manipulation

Remember to clear environment bc we are starting with the same info but new stuff.

Load in the litters data

```{r}
litters_df = read_csv("data/FAS_litters.csv")
litters_df = janitor::clean_names(litters_df)
litters_df
```

this is other data from chatgpt to clean data into all dbl

```{r}
library(readr)
library(janitor)

litters_df =
  read_csv(
    "data/FAS_litters.csv",
    na = c("", "NA", "."),
    col_types = cols(
      Group = col_character(),
      `Litter Number` = col_character(),
      `GD0 weight` = col_double(),
      `GD18 weight` = col_double(),
      `GD of Birth` = col_double(),
      `Pups born alive` = col_double(),
      `Pups dead @ birth` = col_double(),
      `Pups survive` = col_double()
    ),
    show_col_types = FALSE
  ) |>
  clean_names()
```





#### lets look at `select`

Choose some columns and not others

```{r}
select(litters_df, group, gd0_weight)
```

selects only those two columns

```{r}
select(litters_df, group, gd0_weight:gd_of_birth)
```

```{r}
select(litters_df, -litter_number)
```

deletes columns

```{r}
select(litters_df, GROUP = group, LITTer_NUmBer = litter_number)
```

^ renames groups

```{r}
rename(litters_df, GROUP = group, LITTer_NUmBer = litter_number)
```

a few helper commands we can find with ?select_helpers
Select helpers

```{r}
select(litters_df, starts_with("gd"))
```

how to pick a column quickly that has the same begining start.

```{r}
select(litters_df, litter_number, everything())
```

```{r}
relocate(litters_df, litter_number)
```

the last two things, puts column `litter_number` in the front.

#### filter

Filter operates on rows

```{r}
filter(litters_df, gd0_weight < 22)
```


```{r}
filter(litters_df, gd0_weight >= 22)
```

this shows the rows that are less than or greater than 22!

```{r}
filter(litters_df, gd_of_birth == 20)
```

double equal sign so that it doesnt SAVE it as a variable

```{r}
filter(litters_df, !gd_of_birth == 20)
```

lets look complex things

```{r}
filter(litters_df, gd0_weight >= 22, gd_of_birth == 20)
```

specifying things we want to keep in our data set

```{r}
filter(litters_df, group == "Mod8")
```

```{r}
filter(litters_df, group %in% c("Mod8", "Con7"))
```
it shows rows in either using mod8 or con7.

#### `mutate`

```{r}
mutate(
  litters_df,
  wt_gain = gd18_weight - gd0_weight,
  group = str_to_lower(group))
```

this didn't work like it should, but basically you are creating a new column
called wt_gain using the other information. Then you change the groups to lowercase.




